{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## yaw"
      ],
      "metadata": {
        "id": "UsRQ2fxE9QBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SelkRDoGVrZ0",
        "outputId": "8baa7f77-0118-48ea-b696-c72627a6d807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQVGfbk_WONz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "modelh5 = tf.keras.models.load_model('/content/drive/MyDrive/light-frame-selection/Yaw_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebNJuGr0NJKC",
        "outputId": "948b88ea-cd91-4aed-913b-7bb3d718df91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import onnx\n",
        "\n",
        "\n",
        "\n",
        "# Use from_function for tf functions\n",
        "onnx_model, _ = tf2onnx.convert.from_keras(modelh5, opset=9)"
      ],
      "metadata": {
        "id": "rh3_2JA4Mdwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx.save(onnx_model, \"model.onnx\")"
      ],
      "metadata": {
        "id": "nbBKfZ8hXGOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "xxx = np.zeros((1, 224, 224, 3), np.float32)\n",
        "\n",
        "\n",
        "sess = ort.InferenceSession(\"/content/model.onnx\")\n",
        "\n",
        "# Set first argument of sess.run to None to use all model outputs in default order\n",
        "# Input/output names are printed by the CLI and can be set with --rename-inputs and --rename-outputs\n",
        "# If using the python API, names are determined from function arg names or TensorSpec names.\n"
      ],
      "metadata": {
        "id": "uGbh6oCrXeir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "tt = time.time()\n",
        "results_ort = sess.run(None, {\"input_2\": xxx})\n",
        "time.time() - tt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_sKezjeDY6",
        "outputId": "c800a024-7e34-4bca-f873-b4a38f81018c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4811058044433594"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_anc = np.argmax(results_ort[2][0])\n",
        "anchors = results_ort[1][0][max_anc]\n",
        "\n",
        "if anchors[1] > 0:\n",
        "    angle_offset = np.arccos(anchors[0])\n",
        "else:\n",
        "    angle_offset = -np.arccos(anchors[0])\n",
        "bin_num = results_ort[2][0].shape[0]\n",
        "wedge = 2. * np.pi / bin_num\n",
        "theta_loc = angle_offset + max_anc * wedge\n",
        "\n",
        "theta = theta_loc + 0 # theta_ray\n",
        "    # object's yaw angle\n",
        "yaw = (np.pi/2 - theta) * 57\n",
        "\n",
        "if yaw < 0 :\n",
        "    yaw = 360 + yaw\n",
        "\n",
        "yaw += 90\n",
        "if yaw > 360:\n",
        "    yaw -= 360\n",
        "\n",
        "yaw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ti-s32rcC_6",
        "outputId": "dd292a19-a069-4caa-a956-753622508b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180.524321694597"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## glare"
      ],
      "metadata": {
        "id": "MaFW_pRk9T2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.mobilenet_v2(weights=\"DEFAULT\")\n",
        "\n",
        "ii=1\n",
        "for param in model.parameters():\n",
        "    if ii < 133:\n",
        "        param.requires_grad = False\n",
        "    ii+=1\n",
        "\n",
        "\n",
        "model.classifier[1] = nn.Sequential(\n",
        "    nn.Dropout(p = 0.2),nn.Linear(1280, 500), nn.ReLU(),nn.Dropout(p = 0.5) ,  nn.Linear(500, num_classes)\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('/content/best_model_epoch_9_cars.pth' , map_location=torch.device('cpu')))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6n3Pr7k9Tgk",
        "outputId": "e755f45f-47a9-4c8a-9d04-5602a082b523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the model\n",
        "import onnx\n",
        "\n",
        "sz = 420\n",
        "x = torch.randn(1, 3, sz, sz, requires_grad=True)\n",
        "torch_out = model(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"glare_9_cars.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=9,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YLDL-qBBPkw",
        "outputId": "31fe7b4a-8f19-47ff-b7e2-b146a830337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"glare_9_cars.onnx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrP2PrlPCt4e",
        "outputId": "f2a22180-bedf-4129-9b92-a0ce1dee2970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input'])\n",
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xxx = np.zeros((1, 3, 420, 420), np.float32)\n",
        "ort_outs = ort_session.run(None, {\"input\":xxx})\n",
        "ort_outs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJClh_rBDOAe",
        "outputId": "3cad1163-398d-48ec-b4ec-2b69040e2eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.9553564,  1.0258516]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgSMQSeSFXMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# angle"
      ],
      "metadata": {
        "id": "GbMsuhjX5fNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.mobilenet_v2(weights=\"DEFAULT\")\n",
        "\n",
        "ii=1\n",
        "for param in model.parameters():\n",
        "    if ii < 0:\n",
        "        param.requires_grad = False\n",
        "    ii+=1\n",
        "\n",
        "\n",
        "model.classifier[1] = nn.Sequential(\n",
        "    nn.Dropout(p = 0.2),nn.Linear(1280, 500), nn.ReLU(),nn.Dropout(p = 0.5) ,  nn.Linear(500, 1)\n",
        ")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('/content/angles_best_model_epoch_20.pth' , map_location=torch.device('cpu')))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"success!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv8y1SC95gHu",
        "outputId": "e387981e-562d-46bd-ec93-dd0d7e177c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 69.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the model\n",
        "import onnx\n",
        "\n",
        "sz = 420\n",
        "x = torch.randn(1, 3, sz, sz, requires_grad=True)\n",
        "torch_out = model(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"angle_mobileNet_20.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=9,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N9lpZHX5wW8",
        "outputId": "cafe91d5-4ca1-4647-cae5-1734bd901942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"angle_mobileNet_20.onnx\")"
      ],
      "metadata": {
        "id": "645etIRg5ytc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xxx = np.zeros((1, 3, 420, 420), np.float32)\n",
        "ort_outs = ort_session.run(None, {\"input\":xxx})\n",
        "ort_outs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVLMRhYu50ws",
        "outputId": "bc9a9b1c-522d-442c-fc0f-22b737075452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-8.878422]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# blur\n"
      ],
      "metadata": {
        "id": "gS0fiXKkjaxc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1rjPFKJjccc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
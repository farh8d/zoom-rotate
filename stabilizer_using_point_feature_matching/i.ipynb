{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 960, 540)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import numpy and OpenCV\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# Read input video\n",
    "cap = cv2.VideoCapture('org_octo.mp4')\n",
    " \n",
    "# Get frame count\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    " \n",
    "# Get width and height of video stream\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    " \n",
    " \n",
    "n_frames , w , h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first frame\n",
    "_, prev = cap.read() \n",
    " \n",
    "# Convert frame to grayscale\n",
    "prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# plt.imshow(prev_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0/100 -  Tracked points : 191\n",
      "Frame: 1/100 -  Tracked points : 186\n",
      "Frame: 2/100 -  Tracked points : 184\n",
      "Frame: 3/100 -  Tracked points : 186\n",
      "Frame: 4/100 -  Tracked points : 191\n",
      "Frame: 5/100 -  Tracked points : 184\n",
      "Frame: 6/100 -  Tracked points : 186\n",
      "Frame: 7/100 -  Tracked points : 173\n",
      "Frame: 8/100 -  Tracked points : 185\n",
      "Frame: 9/100 -  Tracked points : 195\n",
      "Frame: 10/100 -  Tracked points : 187\n",
      "Frame: 11/100 -  Tracked points : 186\n",
      "Frame: 12/100 -  Tracked points : 193\n",
      "Frame: 13/100 -  Tracked points : 198\n",
      "Frame: 14/100 -  Tracked points : 191\n",
      "Frame: 15/100 -  Tracked points : 183\n",
      "Frame: 16/100 -  Tracked points : 184\n",
      "Frame: 17/100 -  Tracked points : 184\n",
      "Frame: 18/100 -  Tracked points : 187\n",
      "Frame: 19/100 -  Tracked points : 192\n",
      "Frame: 20/100 -  Tracked points : 196\n",
      "Frame: 21/100 -  Tracked points : 189\n",
      "Frame: 22/100 -  Tracked points : 192\n",
      "Frame: 23/100 -  Tracked points : 192\n",
      "Frame: 24/100 -  Tracked points : 191\n",
      "Frame: 25/100 -  Tracked points : 197\n",
      "Frame: 26/100 -  Tracked points : 188\n",
      "Frame: 27/100 -  Tracked points : 196\n",
      "Frame: 28/100 -  Tracked points : 187\n",
      "Frame: 29/100 -  Tracked points : 190\n",
      "Frame: 30/100 -  Tracked points : 190\n",
      "Frame: 31/100 -  Tracked points : 192\n",
      "Frame: 32/100 -  Tracked points : 179\n",
      "Frame: 33/100 -  Tracked points : 188\n",
      "Frame: 34/100 -  Tracked points : 193\n",
      "Frame: 35/100 -  Tracked points : 169\n",
      "Frame: 36/100 -  Tracked points : 187\n",
      "Frame: 37/100 -  Tracked points : 187\n",
      "Frame: 38/100 -  Tracked points : 181\n",
      "Frame: 39/100 -  Tracked points : 175\n",
      "Frame: 40/100 -  Tracked points : 188\n",
      "Frame: 41/100 -  Tracked points : 188\n",
      "Frame: 42/100 -  Tracked points : 188\n",
      "Frame: 43/100 -  Tracked points : 188\n",
      "Frame: 44/100 -  Tracked points : 170\n",
      "Frame: 45/100 -  Tracked points : 190\n",
      "Frame: 46/100 -  Tracked points : 174\n",
      "Frame: 47/100 -  Tracked points : 173\n",
      "Frame: 48/100 -  Tracked points : 190\n",
      "Frame: 49/100 -  Tracked points : 161\n",
      "Frame: 50/100 -  Tracked points : 194\n",
      "Frame: 51/100 -  Tracked points : 189\n",
      "Frame: 52/100 -  Tracked points : 195\n",
      "Frame: 53/100 -  Tracked points : 190\n",
      "Frame: 54/100 -  Tracked points : 180\n",
      "Frame: 55/100 -  Tracked points : 190\n",
      "Frame: 56/100 -  Tracked points : 187\n",
      "Frame: 57/100 -  Tracked points : 186\n",
      "Frame: 58/100 -  Tracked points : 189\n",
      "Frame: 59/100 -  Tracked points : 189\n",
      "Frame: 60/100 -  Tracked points : 193\n",
      "Frame: 61/100 -  Tracked points : 193\n",
      "Frame: 62/100 -  Tracked points : 194\n",
      "Frame: 63/100 -  Tracked points : 194\n",
      "Frame: 64/100 -  Tracked points : 189\n",
      "Frame: 65/100 -  Tracked points : 189\n",
      "Frame: 66/100 -  Tracked points : 192\n",
      "Frame: 67/100 -  Tracked points : 179\n",
      "Frame: 68/100 -  Tracked points : 194\n",
      "Frame: 69/100 -  Tracked points : 181\n",
      "Frame: 70/100 -  Tracked points : 190\n",
      "Frame: 71/100 -  Tracked points : 194\n",
      "Frame: 72/100 -  Tracked points : 191\n",
      "Frame: 73/100 -  Tracked points : 196\n",
      "Frame: 74/100 -  Tracked points : 189\n",
      "Frame: 75/100 -  Tracked points : 193\n",
      "Frame: 76/100 -  Tracked points : 191\n",
      "Frame: 77/100 -  Tracked points : 200\n",
      "Frame: 78/100 -  Tracked points : 190\n",
      "Frame: 79/100 -  Tracked points : 195\n",
      "Frame: 80/100 -  Tracked points : 197\n",
      "Frame: 81/100 -  Tracked points : 181\n",
      "Frame: 82/100 -  Tracked points : 197\n",
      "Frame: 83/100 -  Tracked points : 195\n",
      "Frame: 84/100 -  Tracked points : 194\n",
      "Frame: 85/100 -  Tracked points : 197\n",
      "Frame: 86/100 -  Tracked points : 192\n",
      "Frame: 87/100 -  Tracked points : 192\n",
      "Frame: 88/100 -  Tracked points : 199\n",
      "Frame: 89/100 -  Tracked points : 198\n",
      "Frame: 90/100 -  Tracked points : 193\n",
      "Frame: 91/100 -  Tracked points : 195\n",
      "Frame: 92/100 -  Tracked points : 195\n",
      "Frame: 93/100 -  Tracked points : 186\n",
      "Frame: 94/100 -  Tracked points : 194\n",
      "Frame: 95/100 -  Tracked points : 188\n",
      "Frame: 96/100 -  Tracked points : 193\n",
      "Frame: 97/100 -  Tracked points : 188\n"
     ]
    }
   ],
   "source": [
    "# Pre-define transformation-store array\n",
    "transforms = np.zeros((n_frames-1, 3), np.float32) \n",
    " \n",
    "for i in range(n_frames-2):\n",
    "  # Detect feature points in previous frame\n",
    "  prev_pts = cv2.goodFeaturesToTrack(prev_gray,\n",
    "                                     maxCorners=200,\n",
    "                                     qualityLevel=0.01,\n",
    "                                     minDistance=30,\n",
    "                                     blockSize=3)\n",
    " \n",
    "  # Read next frame\n",
    "  success, curr = cap.read()\n",
    "  if not success:\n",
    "    break\n",
    " \n",
    "  # Convert to grayscale\n",
    "  curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY) \n",
    " \n",
    "  # Calculate optical flow (i.e. track feature points)\n",
    "  curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None) \n",
    " \n",
    "  # Sanity check\n",
    "  assert prev_pts.shape == curr_pts.shape \n",
    " \n",
    "  # Filter only valid points\n",
    "  idx = np.where(status==1)[0]\n",
    "  prev_pts = prev_pts[idx]\n",
    "  curr_pts = curr_pts[idx]\n",
    " \n",
    "  #Find transformation matrix\n",
    "  m = cv2.estimateAffine2D(prev_pts, curr_pts) #will only work with OpenCV-3 or less\n",
    " \n",
    "  # Extract traslation\n",
    "#   print(\"fff\" , m)\n",
    "  dx = m[0][0,2]\n",
    "  dy = m[0][1,2]\n",
    " \n",
    "  # Extract rotation angle\n",
    "  da = np.arctan2(m[0][1,0], m[0][0,0])\n",
    " \n",
    "  # Store transformation\n",
    "  transforms[i] = [dx,dy,da]\n",
    " \n",
    "  # Move to next frame\n",
    "  prev_gray = curr_gray\n",
    " \n",
    "  print(\"Frame: \" + str(i) +  \"/\" + str(n_frames) + \" -  Tracked points : \" + str(len(prev_pts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = np.cumsum(transforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTHING_RADIUS = 5\n",
    "\n",
    "def movingAverage(curve, radius):\n",
    "  window_size = 2 * radius + 1\n",
    "  # Define the filter\n",
    "  f = np.ones(window_size)/window_size\n",
    "  # Add padding to the boundaries\n",
    "  curve_pad = np.lib.pad(curve, (radius, radius), 'edge')\n",
    "  # Apply convolution\n",
    "  curve_smoothed = np.convolve(curve_pad, f, mode='same')\n",
    "  # Remove padding\n",
    "  curve_smoothed = curve_smoothed[radius:-radius]\n",
    "  # return smoothed curve\n",
    "  return curve_smoothed\n",
    "\n",
    "\n",
    "def smooth(trajectory):\n",
    "  smoothed_trajectory = np.copy(trajectory)\n",
    "  # Filter the x, y and angle curves\n",
    "  for i in range(3):\n",
    "    smoothed_trajectory[:,i] = movingAverage(trajectory[:,i], radius=SMOOTHING_RADIUS)\n",
    " \n",
    "  return smoothed_trajectory\n",
    "\n",
    "\n",
    "trajectory = np.cumsum(transforms, axis=0)\n",
    "\n",
    "smoothed_trajectory = smooth(trajectory)\n",
    "difference = smoothed_trajectory - trajectory\n",
    " \n",
    "# Calculate newer transformation array\n",
    "transforms_smooth = transforms + difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixBorder(frame):\n",
    "  s = frame.shape\n",
    "  # Scale the image 4% without moving the center\n",
    "  T = cv2.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.04)\n",
    "  frame = cv2.warpAffine(frame, T, (s[1], s[0]))\n",
    "  return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the codec for output video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "\n",
    "fps = 3\n",
    "# Set up output video\n",
    "out = cv2.VideoWriter('video_out.mp4', fourcc, fps, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  (540, 1920, 3)\n",
      "1  :  (540, 1920, 3)\n",
      "2  :  (540, 1920, 3)\n",
      "3  :  (540, 1920, 3)\n",
      "4  :  (540, 1920, 3)\n",
      "5  :  (540, 1920, 3)\n",
      "6  :  (540, 1920, 3)\n",
      "7  :  (540, 1920, 3)\n",
      "8  :  (540, 1920, 3)\n",
      "9  :  (540, 1920, 3)\n",
      "10  :  (540, 1920, 3)\n",
      "11  :  (540, 1920, 3)\n",
      "12  :  (540, 1920, 3)\n",
      "13  :  (540, 1920, 3)\n",
      "14  :  (540, 1920, 3)\n",
      "15  :  (540, 1920, 3)\n",
      "16  :  (540, 1920, 3)\n",
      "17  :  (540, 1920, 3)\n",
      "18  :  (540, 1920, 3)\n",
      "19  :  (540, 1920, 3)\n",
      "20  :  (540, 1920, 3)\n",
      "21  :  (540, 1920, 3)\n",
      "22  :  (540, 1920, 3)\n",
      "23  :  (540, 1920, 3)\n",
      "24  :  (540, 1920, 3)\n",
      "25  :  (540, 1920, 3)\n",
      "26  :  (540, 1920, 3)\n",
      "27  :  (540, 1920, 3)\n",
      "28  :  (540, 1920, 3)\n",
      "29  :  (540, 1920, 3)\n",
      "30  :  (540, 1920, 3)\n",
      "31  :  (540, 1920, 3)\n",
      "32  :  (540, 1920, 3)\n",
      "33  :  (540, 1920, 3)\n",
      "34  :  (540, 1920, 3)\n",
      "35  :  (540, 1920, 3)\n",
      "36  :  (540, 1920, 3)\n",
      "37  :  (540, 1920, 3)\n",
      "38  :  (540, 1920, 3)\n",
      "39  :  (540, 1920, 3)\n",
      "40  :  (540, 1920, 3)\n",
      "41  :  (540, 1920, 3)\n",
      "42  :  (540, 1920, 3)\n",
      "43  :  (540, 1920, 3)\n",
      "44  :  (540, 1920, 3)\n",
      "45  :  (540, 1920, 3)\n",
      "46  :  (540, 1920, 3)\n",
      "47  :  (540, 1920, 3)\n",
      "48  :  (540, 1920, 3)\n",
      "49  :  (540, 1920, 3)\n",
      "50  :  (540, 1920, 3)\n",
      "51  :  (540, 1920, 3)\n",
      "52  :  (540, 1920, 3)\n",
      "53  :  (540, 1920, 3)\n",
      "54  :  (540, 1920, 3)\n",
      "55  :  (540, 1920, 3)\n",
      "56  :  (540, 1920, 3)\n",
      "57  :  (540, 1920, 3)\n",
      "58  :  (540, 1920, 3)\n",
      "59  :  (540, 1920, 3)\n",
      "60  :  (540, 1920, 3)\n",
      "61  :  (540, 1920, 3)\n",
      "62  :  (540, 1920, 3)\n",
      "63  :  (540, 1920, 3)\n",
      "64  :  (540, 1920, 3)\n",
      "65  :  (540, 1920, 3)\n",
      "66  :  (540, 1920, 3)\n",
      "67  :  (540, 1920, 3)\n",
      "68  :  (540, 1920, 3)\n",
      "69  :  (540, 1920, 3)\n",
      "70  :  (540, 1920, 3)\n",
      "71  :  (540, 1920, 3)\n",
      "72  :  (540, 1920, 3)\n",
      "73  :  (540, 1920, 3)\n",
      "74  :  (540, 1920, 3)\n",
      "75  :  (540, 1920, 3)\n",
      "76  :  (540, 1920, 3)\n",
      "77  :  (540, 1920, 3)\n",
      "78  :  (540, 1920, 3)\n",
      "79  :  (540, 1920, 3)\n",
      "80  :  (540, 1920, 3)\n",
      "81  :  (540, 1920, 3)\n",
      "82  :  (540, 1920, 3)\n",
      "83  :  (540, 1920, 3)\n",
      "84  :  (540, 1920, 3)\n",
      "85  :  (540, 1920, 3)\n",
      "86  :  (540, 1920, 3)\n",
      "87  :  (540, 1920, 3)\n",
      "88  :  (540, 1920, 3)\n",
      "89  :  (540, 1920, 3)\n",
      "90  :  (540, 1920, 3)\n",
      "91  :  (540, 1920, 3)\n",
      "92  :  (540, 1920, 3)\n",
      "93  :  (540, 1920, 3)\n",
      "94  :  (540, 1920, 3)\n",
      "95  :  (540, 1920, 3)\n",
      "96  :  (540, 1920, 3)\n",
      "97  :  (540, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reset stream to first frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) \n",
    "\n",
    "all_frames = []\n",
    "\n",
    "cc = 0 \n",
    "# Write n_frames-1 transformed frames\n",
    "for i in range(n_frames-2):\n",
    "  # Read next frame\n",
    "  success, frame = cap.read()\n",
    "  if not success:\n",
    "    break\n",
    " \n",
    "  # Extract transformations from the new transformation array\n",
    "  dx = transforms_smooth[i,0]\n",
    "  dy = transforms_smooth[i,1]\n",
    "  da = transforms_smooth[i,2]\n",
    " \n",
    "  # Reconstruct transformation matrix accordingly to new values\n",
    "  m = np.zeros((2,3), np.float32)\n",
    "  m[0,0] = np.cos(da)\n",
    "  m[0,1] = -np.sin(da)\n",
    "  m[1,0] = np.sin(da)\n",
    "  m[1,1] = np.cos(da)\n",
    "  m[0,2] = dx\n",
    "  m[1,2] = dy\n",
    " \n",
    "  # Apply affine wrapping to the given frame\n",
    "  frame_stabilized = cv2.warpAffine(frame, m, (w,h))\n",
    " \n",
    "  # Fix border artifacts\n",
    "  frame_stabilized = fixBorder(frame_stabilized) \n",
    " \n",
    "  # Write the frame to the file\n",
    "  frame_out = cv2.hconcat([frame, frame_stabilized])\n",
    " \n",
    "  print(cc , \" : \", frame_out.shape)\n",
    "  cc+=1\n",
    "  all_frames.append(frame_out)\n",
    "  cv2.imshow(\"Before and After\", frame_out)\n",
    "\n",
    "  \n",
    "  cv2.waitKey(10)\n",
    "  out.write(frame_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def convert_frames_to_video(frames1, output_path, fps):\n",
    "    \n",
    "    # Get frame dimensions from the first frame\n",
    "    frame = frames1[0]\n",
    "    height, width, channels = frame.shape\n",
    "    \n",
    "    # Create the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for frame in frames1:\n",
    "        # Read the frame image\n",
    "        \n",
    "        # Write the frame to the video\n",
    "        video.write(frame)\n",
    "    \n",
    "    # Release the video writer\n",
    "    video.release()\n",
    "\n",
    "\n",
    "output_folder = \" \"\n",
    "output_video_path = \"path_to_output_video.mp4\"\n",
    "fps = 5\n",
    "\n",
    "# Extract frames from the video\n",
    "\n",
    "# Convert frames back to video\n",
    "convert_frames_to_video(all_frames, output_video_path, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
